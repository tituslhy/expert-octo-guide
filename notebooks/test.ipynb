{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe67a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19a775a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent.workflow import FunctionAgent, ToolCallResult, ToolCall\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "agent = FunctionAgent(\n",
    "    tools=[multiply, add],\n",
    "    llm=Ollama(\"qwen2.5\", temperature=0),\n",
    ")\n",
    "ctx = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dbf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentWorkflow,\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d060921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input=[ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='What is 2*3?')])] current_agent_name='Agent'\n",
      "delta='' response='' current_agent_name='Agent' tool_calls=[ToolSelection(tool_id='multiply', tool_name='multiply', tool_kwargs={'a': 2, 'b': 3})] raw={'model': 'qwen2.5', 'created_at': '2025-04-19T06:16:13.413345Z', 'done': False, 'done_reason': None, 'total_duration': None, 'load_duration': None, 'prompt_eval_count': None, 'prompt_eval_duration': None, 'eval_count': None, 'eval_duration': None, 'message': Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='multiply', arguments={'a': 2, 'b': 3}))])}\n",
      "delta='' response='' current_agent_name='Agent' tool_calls=[] raw={'model': 'qwen2.5', 'created_at': '2025-04-19T06:16:13.446002Z', 'done': True, 'done_reason': 'stop', 'total_duration': 568350667, 'load_duration': 28162125, 'prompt_eval_count': 267, 'prompt_eval_duration': 145591250, 'eval_count': 25, 'eval_duration': 392345417, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'usage': {'prompt_tokens': 267, 'completion_tokens': 25, 'total_tokens': 292}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "handler = agent.run(user_msg=\"What is 2*3?\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, AgentStream):\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "   #      print(event.response)  # the current full response\n",
    "   #      print(event.raw)  # the raw llm api response\n",
    "   #      print(event.current_agent_name)  # the current agent name\n",
    "   #  elif isinstance(event, AgentInput):\n",
    "   #     print(event.input)  # the current input messages\n",
    "   #     print(event.current_agent_name)  # the current agent name\n",
    "   #  elif isinstance(event, AgentOutput):\n",
    "   #     print(event.response)  # the current full response\n",
    "   #     print(event.tool_calls)  # the selected tool calls, if any\n",
    "   #     print(event.raw)  # the raw llm api response\n",
    "   #  elif isinstance(event, ToolCallResult):\n",
    "   #     print(event.tool_name)  # the tool name\n",
    "   #     print(event.tool_kwargs)  # the tool kwargs\n",
    "   #     print(event.tool_output)  # the tool output\n",
    "   #  elif isinstance(event, ToolCall):\n",
    "   #      print(event.tool_name)  # the tool name\n",
    "   #      print(event.tool_kwargs)  # the tool kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38b2d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = agent.run(user_msg=\"What is 2*3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297d6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "from llama_index.core.memory import ChatMemoryBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3878b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1346d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.put(\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM, \n",
    "        content=\"You are a helpful AI assistant. You can access tools using MCP servers if available.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b754bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.put(\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=\"What is the capital of France?\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f24cac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = memory.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4751a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"qwen2.5\", temperature=0)\n",
    "engine = SimpleChatEngine.from_defaults(\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb6477ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='Hello! The capital of France is Paris. Do you have any other questions about France or need more information on a specific topic?', sources=[], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.chat(\"Hi!\", chat_history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3c390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
